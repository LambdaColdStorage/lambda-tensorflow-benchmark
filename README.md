
This is the code used for a few of the blog posts on: https://lambdalabs.com/blog including:

- 2080 Ti Deep Learning Benchmarks: https://lambdalabs.com/blog/2080-ti-deep-learning-benchmarks/

Environment:
- OS: Ubuntu 18.04
- TensorFlow version: 1.15.3
- CUDA Version 10.0
- CUDNN Version 7.6.2

#### Step One: Clone benchmark repo


```
git clone https://github.com/lambdal/lambda-tensorflow-benchmark.git
```

#### Step Two: Run benchmark with thermal profile

```
./batch_benchmark.sh min_num_gpus max_num_gpus num_runs num_batches_per_run thermal_sampling_frequency
python display_thermal.py path-to-thermal.log --thermal_threshold

# example of benchmarking 4 2080_Ti (all used), 1 run, 100 batches per run, measuring thermal every 2 second. 2080_Ti throttles at 89 C.
./batch_benchmark.sh 4 4 1 100 2 config_resnet50_replicated_fp32_train_syn
python display_thermal.py path-to-thermal/1 --thermal_threshold 89

```

#### AMD

Follow the guidance [here](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream)

```
alias drun='sudo docker run \
      -it \
      --network=host \
      --device=/dev/kfd \
      --device=/dev/dri \
      --ipc=host \
      --shm-size 16G \
      --group-add video \
      --cap-add=SYS_PTRACE \
      --security-opt seccomp=unconfined \
      -v $HOME/dockerx:/dockerx'

drun rocm/tensorflow:latest

apt install rocm-libs hipcub miopen-hip
pip3 install --user tensorflow-rocm --upgrade
pip3 install tensorflow

cd /home/dockerx
git clone https://github.com/lambdal/lambda-tensorflow-benchmark.git --recursive
git checkout tf2
git submodule update --init --recursive

./batch_benchmark.sh 1 1 1 100 2 config_resnet50_replicated_fp32_train_syn
```


#### Note

Use large num_batches_per_run for a thorough test.


<!-- #### Step Two: Run benchmark

* Input proper gpu_indices (a comma seperated list, default 0) and num_iterations (default 10)
```
cd lambda-tensorflow-benchmark
./benchmark.sh gpu_indices num_iterations
```

#### Step Three: Report results

* Check the repo directory for folder \<cpu>-\<gpu>.logs (generated by benchmark.sh)
* Use the same num_iterations and gpu_indices for both benchmarking and reporting.
```
./report.sh <cpu>-<gpu>.logs
```

#### Batch process:

```
TF_XLA_FLAGS=--tf_xla_auto_jit=2 ./batch_benchmark.sh min_num_gpus max_num_gpus num_iterations

./report.sh <cpu>-<gpu>.logs

./gether.sh
```

 -->
