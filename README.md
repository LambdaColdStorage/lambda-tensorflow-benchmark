
This is the code used for a few of the blog posts on: https://lambdalabs.com/blog including:

- 2080 Ti Deep Learning Benchmarks: https://lambdalabs.com/blog/2080-ti-deep-learning-benchmarks/

Environment:
- OS: Ubuntu 18.04
- TensorFlow version: 1.14.0
- CUDA Version 10.0
- CUDNN Version 7.6.2

#### Step One: Clone benchmark repo


```
git clone https://github.com/lambdal/lambda-tensorflow-benchmark.git --recursive

git checkout tf2

git submodule update --init --recursive
```

#### Step Two: Run benchmark with thermal profile

```
TF_XLA_FLAGS=--tf_xla_auto_jit=2 ./batch_benchmark.sh min_num_gpus max_num_gpus num_runs num_batches_per_run thermal_sampling_frequency
python display_thermal.py path-to-thermal.log --thermal_threshold

# example of benchmarking 4 2080_Ti (all used), 1 run, 200 batches per run, measuring thermal every 2 second. 2080_Ti throttles at 89 C.
TF_XLA_FLAGS=--tf_xla_auto_jit=2 ./batch_benchmark.sh 4 4 1 200 2
python display_thermal.py i9-7920X-GeForce_RTX_2080_Ti.logs/resnet152-syn-replicated-fp32-4gpus-32-1-thermal.log --thermal_threshold 89

```

#### AMD

Follow the guidance [here](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream)

```
alias drun='sudo docker run \
      -it \
      --network=host \
      --device=/dev/kfd \
      --device=/dev/dri \
      --ipc=host \
      --shm-size 16G \
      --group-add video \
      --cap-add=SYS_PTRACE \
      --security-opt seccomp=unconfined \
      -v $HOME/dockerx:/dockerx'

drun rocm/tensorflow:latest

apt install rocm-libs hipcub miopen-hip
pip3 install --user tensorflow-rocm --upgrade
pip3 install tensorflow

cd /home/dockerx
git clone https://github.com/lambdal/lambda-tensorflow-benchmark.git --recursive
git checkout tf2
git submodule update --init --recursive

./batch_benchmark.sh 1 1 1 100 2 amd
```


#### Note

Use large num_batches_per_run for a thorough test.


<!-- #### Step Two: Run benchmark

* Input proper gpu_indices (a comma seperated list, default 0) and num_iterations (default 10)
```
cd lambda-tensorflow-benchmark
./benchmark.sh gpu_indices num_iterations
```

#### Step Three: Report results

* Check the repo directory for folder \<cpu>-\<gpu>.logs (generated by benchmark.sh)
* Use the same num_iterations and gpu_indices for both benchmarking and reporting.
```
./report.sh <cpu>-<gpu>.logs num_iterations gpu_indices
```

#### Batch process:

```
TF_XLA_FLAGS=--tf_xla_auto_jit=2 ./batch_benchmark.sh min_num_gpus max_num_gpus num_iterations

./batch_report.sh <cpu>-<gpu>.logs min_num_gpus max_num_gpus num_iterations

./gether.sh
```

 -->
